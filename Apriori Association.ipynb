{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apriori Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['United Kingdom' 'France' 'Australia' 'Netherlands' 'Germany' 'Norway'\n",
      " 'EIRE' 'Switzerland' 'Spain' 'Poland' 'Portugal' 'Italy' 'Belgium'\n",
      " 'Lithuania' 'Japan' 'Iceland' 'Channel Islands' 'Denmark' 'Cyprus'\n",
      " 'Sweden' 'Austria' 'Israel' 'Finland' 'Bahrain' 'Greece' 'Hong Kong'\n",
      " 'Singapore' 'Lebanon' 'United Arab Emirates' 'Saudi Arabia'\n",
      " 'Czech Republic' 'Canada' 'Unspecified' 'Brazil' 'USA'\n",
      " 'European Community' 'Malta' 'RSA']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Loading the Data\n",
    "data = pd.read_csv('D:/7. JUL - DEC 2021/TEDP/Data Science Course/Online_Retail.csv')\n",
    "data.head()\n",
    "\n",
    "\n",
    "# Exploring the columns of the data\n",
    "data.columns\n",
    "\n",
    "\n",
    "# Exploring the different regions of transactions\n",
    "print(data.Country.unique())\n",
    "\n",
    "\n",
    "\n",
    "# Stripping extra spaces in the description\n",
    "data['Description'] = data['Description'].str.strip()\n",
    " \n",
    "# Dropping the rows without any invoice number\n",
    "data.dropna(axis = 0, subset =['InvoiceNo'], inplace = True)\n",
    "data['InvoiceNo'] = data['InvoiceNo'].astype('str')\n",
    " \n",
    "# Dropping all transactions which were done on credit\n",
    "data = data[~data['InvoiceNo'].str.contains('C')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transactions done in France\n",
    "basket_France = (data[data['Country'] ==\"France\"]\n",
    "          .groupby(['InvoiceNo', 'Description'])['Quantity']\n",
    "          .sum().unstack().reset_index().fillna(0)\n",
    "          .set_index('InvoiceNo'))\n",
    " \n",
    "# Transactions done in the United Kingdom\n",
    "basket_UK = (data[data['Country'] ==\"United Kingdom\"]\n",
    "          .groupby(['InvoiceNo', 'Description'])['Quantity']\n",
    "          .sum().unstack().reset_index().fillna(0)\n",
    "          .set_index('InvoiceNo'))\n",
    " \n",
    "# Transactions done in Portugal\n",
    "basket_Por = (data[data['Country'] ==\"Portugal\"]\n",
    "          .groupby(['InvoiceNo', 'Description'])['Quantity']\n",
    "          .sum().unstack().reset_index().fillna(0)\n",
    "          .set_index('InvoiceNo'))\n",
    " \n",
    "basket_Sweden = (data[data['Country'] ==\"Sweden\"]\n",
    "          .groupby(['InvoiceNo', 'Description'])['Quantity']\n",
    "          .sum().unstack().reset_index().fillna(0)\n",
    "          .set_index('InvoiceNo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the hot encoding function to make the data suitable\n",
    "# for the concerned libraries\n",
    "def hot_encode(x):\n",
    "    if(x<= 0):\n",
    "        return 0\n",
    "    if(x>= 1):\n",
    "        return 1\n",
    " \n",
    "# Encoding the datasets\n",
    "basket_encoded = basket_France.applymap(hot_encode)\n",
    "basket_France = basket_encoded\n",
    " \n",
    "basket_encoded = basket_UK.applymap(hot_encode)\n",
    "basket_UK = basket_encoded\n",
    " \n",
    "basket_encoded = basket_Por.applymap(hot_encode)\n",
    "basket_Por = basket_encoded\n",
    " \n",
    "basket_encoded = basket_Sweden.applymap(hot_encode)\n",
    "basket_Sweden = basket_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           antecedents  \\\n",
      "44                        (JUMBO BAG WOODLAND ANIMALS)   \n",
      "260  (RED TOADSTOOL LED NIGHT LIGHT, PLASTERS IN TI...   \n",
      "272  (RED TOADSTOOL LED NIGHT LIGHT, PLASTERS IN TI...   \n",
      "302  (SET/20 RED RETROSPOT PAPER NAPKINS, SET/6 RED...   \n",
      "300  (SET/6 RED SPOTTY PAPER PLATES, SET/20 RED RET...   \n",
      "\n",
      "                         consequents  antecedent support  consequent support  \\\n",
      "44                         (POSTAGE)            0.076531            0.765306   \n",
      "260                        (POSTAGE)            0.051020            0.765306   \n",
      "272                        (POSTAGE)            0.053571            0.765306   \n",
      "302  (SET/6 RED SPOTTY PAPER PLATES)            0.102041            0.127551   \n",
      "300    (SET/6 RED SPOTTY PAPER CUPS)            0.102041            0.137755   \n",
      "\n",
      "      support  confidence      lift  leverage  conviction  \n",
      "44   0.076531       1.000  1.306667  0.017961         inf  \n",
      "260  0.051020       1.000  1.306667  0.011974         inf  \n",
      "272  0.053571       1.000  1.306667  0.012573         inf  \n",
      "302  0.099490       0.975  7.644000  0.086474   34.897959  \n",
      "300  0.099490       0.975  7.077778  0.085433   34.489796  \n"
     ]
    }
   ],
   "source": [
    "# Building the model\n",
    "frq_items = apriori(basket_France, min_support = 0.05, use_colnames = True)\n",
    " \n",
    "# Collecting the inferred rules in a dataframe\n",
    "rules = association_rules(frq_items, metric =\"lift\", min_threshold = 1)\n",
    "rules = rules.sort_values(['confidence', 'lift'], ascending =[False, False])\n",
    "print(rules.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 87.1 GiB for an array with shape (313236, 2, 18668) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-f6b0391a6bfa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfrq_items\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapriori\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbasket_UK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_support\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_colnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mrules\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0massociation_rules\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrq_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m\"lift\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_threshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mrules\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'confidence'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lift'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\envs\\tensorflow\\lib\\site-packages\\mlxtend\\frequent_patterns\\apriori.py\u001b[0m in \u001b[0;36mapriori\u001b[1;34m(df, min_support, use_colnames, max_len, verbose, low_memory)\u001b[0m\n\u001b[0;32m    300\u001b[0m                     \u001b[0m_bools\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_bools\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcombin\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mall_ones\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0m_bools\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcombin\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[0msupport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_bools\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_sparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 87.1 GiB for an array with shape (313236, 2, 18668) and data type int64"
     ]
    }
   ],
   "source": [
    "frq_items = apriori(basket_UK, min_support = 0.01, use_colnames = True)\n",
    "rules = association_rules(frq_items, metric =\"lift\", min_threshold = 1)\n",
    "rules = rules.sort_values(['confidence', 'lift'], ascending =[False, False])\n",
    "print(rules.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             antecedents                          consequents  \\\n",
      "1170  (SET 12 COLOUR PENCILS DOLLY GIRL)     (SET 12 COLOUR PENCILS SPACEBOY)   \n",
      "1171    (SET 12 COLOUR PENCILS SPACEBOY)   (SET 12 COLOUR PENCILS DOLLY GIRL)   \n",
      "1172  (SET 12 COLOUR PENCILS DOLLY GIRL)   (SET OF 4 KNICK KNACK TINS LONDON)   \n",
      "1173  (SET OF 4 KNICK KNACK TINS LONDON)   (SET 12 COLOUR PENCILS DOLLY GIRL)   \n",
      "1174  (SET 12 COLOUR PENCILS DOLLY GIRL)  (SET OF 4 KNICK KNACK TINS POPPIES)   \n",
      "\n",
      "      antecedent support  consequent support   support  confidence       lift  \\\n",
      "1170            0.051724            0.051724  0.051724         1.0  19.333333   \n",
      "1171            0.051724            0.051724  0.051724         1.0  19.333333   \n",
      "1172            0.051724            0.051724  0.051724         1.0  19.333333   \n",
      "1173            0.051724            0.051724  0.051724         1.0  19.333333   \n",
      "1174            0.051724            0.051724  0.051724         1.0  19.333333   \n",
      "\n",
      "      leverage  conviction  \n",
      "1170  0.049049         inf  \n",
      "1171  0.049049         inf  \n",
      "1172  0.049049         inf  \n",
      "1173  0.049049         inf  \n",
      "1174  0.049049         inf  \n"
     ]
    }
   ],
   "source": [
    "frq_items = apriori(basket_Por, min_support = 0.05, use_colnames = True)\n",
    "rules = association_rules(frq_items, metric =\"lift\", min_threshold = 1)\n",
    "rules = rules.sort_values(['confidence', 'lift'], ascending =[False, False])\n",
    "print(rules.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           antecedents                     consequents  \\\n",
      "0        (12 PENCILS SMALL TUBE SKULL)   (PACK OF 72 SKULL CAKE CASES)   \n",
      "1        (PACK OF 72 SKULL CAKE CASES)   (12 PENCILS SMALL TUBE SKULL)   \n",
      "4       (ASSORTED BOTTLE TOP  MAGNETS)         (36 DOILIES DOLLY GIRL)   \n",
      "5              (36 DOILIES DOLLY GIRL)  (ASSORTED BOTTLE TOP  MAGNETS)   \n",
      "180  (CHILDRENS CUTLERY CIRCUS PARADE)  (CHILDRENS CUTLERY DOLLY GIRL)   \n",
      "\n",
      "     antecedent support  consequent support   support  confidence  lift  \\\n",
      "0              0.055556            0.055556  0.055556         1.0  18.0   \n",
      "1              0.055556            0.055556  0.055556         1.0  18.0   \n",
      "4              0.055556            0.055556  0.055556         1.0  18.0   \n",
      "5              0.055556            0.055556  0.055556         1.0  18.0   \n",
      "180            0.055556            0.055556  0.055556         1.0  18.0   \n",
      "\n",
      "     leverage  conviction  \n",
      "0    0.052469         inf  \n",
      "1    0.052469         inf  \n",
      "4    0.052469         inf  \n",
      "5    0.052469         inf  \n",
      "180  0.052469         inf  \n"
     ]
    }
   ],
   "source": [
    "frq_items = apriori(basket_Sweden, min_support = 0.05, use_colnames = True)\n",
    "rules = association_rules(frq_items, metric =\"lift\", min_threshold = 1)\n",
    "rules = rules.sort_values(['confidence', 'lift'], ascending =[False, False])\n",
    "print(rules.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
